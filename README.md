# ğŸš¢ Titanic - Machine Learning Project

## ğŸ¯ Má»¥c tiÃªu
Dá»± Ã¡n nháº±m **dá»± Ä‘oÃ¡n kháº£ nÄƒng sá»‘ng sÃ³t cá»§a hÃ nh khÃ¡ch trÃªn tÃ u Titanic** dá»±a trÃªn dá»¯ liá»‡u nhÃ¢n kháº©u há»c vÃ  thÃ´ng tin vÃ©.  
Táº­p trung vÃ o viá»‡c **xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u (missing values)**, **ká»¹ thuáº­t feature engineering nÃ¢ng cao**, vÃ  **xÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y á»•n Ä‘á»‹nh, trÃ¡nh data leakage**.

---

## ğŸ§© Tá»•ng quan quy trÃ¬nh

1. **Náº¡p dá»¯ liá»‡u gá»‘c (`train.csv`, `test.csv`)**
2. **PhÃ¢n tÃ­ch sÆ¡ bá»™ (EDA)**: quan sÃ¡t phÃ¢n phá»‘i cá»§a `Survived`, `Sex`, `Pclass`, `Embarked`, v.v.
3. **Táº¡o ba chiáº¿n lÆ°á»£c xá»­ lÃ½ missing values**:
   - Median imputation
   - Group median (theo Sex + Pclass)
   - Model-based imputation (RandomForest)
4. **Feature Engineering nÃ¢ng cao** (FamilySize, Title, Deck, FarePerPerson, AgeClass, â€¦)
5. **TÃ¡ch dá»¯ liá»‡u sá»›m Ä‘á»ƒ chá»‘ng data leakage** (train/validation)
6. **Huáº¥n luyá»‡n & tuning mÃ´ hÃ¬nh** (Random Forest, XGBoost, Logistic Regression, Ensemble)
7. **ÄÃ¡nh giÃ¡ tá»«ng biáº¿n thá»ƒ & táº¡o VotingClassifier**
8. **Ãp dá»¥ng pipeline lÃªn táº­p test vÃ  sinh `submission.csv`**

---

## ğŸ§  Chi tiáº¿t cÃ¡c bÆ°á»›c

### 1ï¸âƒ£ Chia dá»¯ liá»‡u & chá»‘ng data leakage
Ngay sau khi Ä‘á»c dá»¯ liá»‡u, dataset `train` Ä‘Æ°á»£c chia thÃ nh:
- `raw_train` (train set)
- `raw_val` (validation set)

â¡ï¸ Má»i bÆ°á»›c xá»­ lÃ½ missing, fit imputer/model Ä‘á»u Ä‘Æ°á»£c huáº¥n luyá»‡n **chá»‰ trÃªn `raw_train`**  
â¡ï¸ Sau Ä‘Ã³ má»›i **apply lÃªn `raw_val`** Ä‘á»ƒ trÃ¡nh rÃ² rá»‰ thÃ´ng tin (data leakage).

---

### 2ï¸âƒ£ Xá»­ lÃ½ Missing Values

#### **A. Median Imputation**
- `Age`, `Fare` â†’ thay báº±ng median cá»§a train.  
- `Embarked` â†’ thay báº±ng mode.  
- Táº¡o cá» `HasCabin` (1 náº¿u cÃ³ Cabin, 0 náº¿u khÃ´ng).  

â¡ï¸ Nhanh, Ä‘Æ¡n giáº£n, baseline á»•n Ä‘á»‹nh.

#### **B. Group Median Imputation (theo Sex + Pclass)**
- `Age` â†’ median theo nhÃ³m `(Sex, Pclass)`.  
- `Fare` â†’ median theo `Pclass`.  
- `Embarked` â†’ mode.  

â¡ï¸ Táº­n dá»¥ng cáº¥u trÃºc nhÃ³m Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.

#### **C. Model-based Imputation**
- Train **RandomForestRegressor** dá»± Ä‘oÃ¡n `Age`.
- Train **RandomForestClassifier** dá»± Ä‘oÃ¡n `Embarked`.
- DÃ¹ng cÃ¡c biáº¿n nhÆ° `Pclass`, `Sex`, `SibSp`, `Parch`, `Fare`, `HasCabin` Ä‘á»ƒ dá»± Ä‘oÃ¡n.  

â¡ï¸ CÃ³ thá»ƒ chÃ­nh xÃ¡c hÆ¡n, nhÆ°ng cáº§n kiá»ƒm soÃ¡t overfitting.  
â¡ï¸ Models Ä‘Æ°á»£c fit **chá»‰ trÃªn raw_train**, apply lÃªn validation/test Ä‘á»ƒ trÃ¡nh leakage.

---

### 3ï¸âƒ£ Feature Engineering (táº¡o Ä‘áº·c trÆ°ng má»›i)

| NhÃ³m | Biáº¿n má»›i | Giáº£i thÃ­ch |
|------|-----------|------------|
| ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Gia Ä‘Ã¬nh | `FamilySize`, `IsAlone`, `FamilyCategory` | CÃ´ Ä‘Æ¡n hay Ä‘i cÃ¹ng ngÆ°á»i thÃ¢n áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng sá»‘ng sÃ³t |
| ğŸ§” Title | `Title`, `TitleAgeType` | TrÃ­ch xuáº¥t tá»« tÃªn (Mr, Mrs, Miss, Master, Rare...) â€” proxy cho giá»›i tÃ­nh & tuá»•i |
| ğŸ’¸ VÃ© & giÃ¡ | `FarePerPerson`, `FareBin`, `FareClass` | Chuáº©n hÃ³a giÃ¡ vÃ© theo sá»‘ ngÆ°á»i vÃ  nhÃ³m giÃ¡ |
| ğŸ›ï¸ Cabin | `Deck`, `HasCabin` | SÃ n tÃ u vÃ  cÃ³ cabin hay khÃ´ng |
| ğŸŸï¸ VÃ© | `TicketPrefix`, `TicketLen` | MÃ£ vÃ© cho tháº¥y háº¡ng/Ä‘iá»ƒm khá»Ÿi hÃ nh |
| ğŸ“Š Tuá»•i | `AgeBin`, `AgeClass` | PhÃ¢n nhÃ³m tuá»•i & tÆ°Æ¡ng tÃ¡c vá»›i Pclass |
| âš¡ TÆ°Æ¡ng tÃ¡c | `ClassSex`, `ClassEmbarked`, `TitleSex`, `WomenChild`, `HighClassFemale` | Domain knowledge (vÃ­ dá»¥: "Women & Children first") |

---

### 4ï¸âƒ£ Tiá»n xá»­ lÃ½ (Preprocessing)
DÃ¹ng `ColumnTransformer`:
- **Numeric** â†’ `StandardScaler`
- **Categorical** â†’ `OneHotEncoder(drop='first', handle_unknown='ignore')`

---

### 5ï¸âƒ£ Huáº¥n luyá»‡n & Tuning mÃ´ hÃ¬nh

#### âš™ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c thá»­ nghiá»‡m:
- Logistic Regression
- Random Forest (tuning qua GridSearchCV)
- XGBoost (tuning qua GridSearchCV)
- Voting Ensemble (soft voting giá»¯a 3 model)

#### ğŸ“ˆ ÄÃ¡nh giÃ¡:
- Accuracy (chÃ­nh xÃ¡c)
- CÃ³ thá»ƒ má»Ÿ rá»™ng thÃªm: Precision, Recall, F1, ROC AUC, Confusion Matrix

#### ğŸ§ª GridSearchCV:
- RandomForest:
  - `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`
- XGBoost:
  - `n_estimators`, `max_depth`, `learning_rate`, `subsample`, `colsample_bytree`

---

### 6ï¸âƒ£ Ensemble Model (VotingClassifier)
- Káº¿t há»£p 3 mÃ´ hÃ¬nh:
  - Logistic Regression
  - Random Forest (best params)
  - XGBoost (best params)
- `voting='soft'` (dá»±a trÃªn xÃ¡c suáº¥t, khÃ´ng pháº£i nhÃ£n cá»©ng)
- Pipeline cuá»‘i cÃ¹ng:
  ```python
  pipe_voting = Pipeline([
      ('pre', preprocessor),
      ('model', voting_classifier)
  ])
